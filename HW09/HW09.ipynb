{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HW09.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUm9E8gAkvkS",
        "outputId": "d6090d2e-5a3d-47b1-acd0-cbcbfdf8a431"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import os\r\n",
        "\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnNNjLzLk65K"
      },
      "source": [
        "os.chdir(\"drive/MyDrive/data/hw09\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5W5BuAMLpTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f16e4e-b3da-47bc-fbc2-b30734063d35"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dropout, Dense\n",
        "from keras import callbacks\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYuH3GjRLpTH"
      },
      "source": [
        "def data_reader(filename:str):\n",
        "    \"\"\"Read the movie reviews with the given filename.\"\"\"\n",
        "    df = pd.read_csv(filename,sep=\",\",header=0)\n",
        "    df[\"sentiment\"].apply(lambda x: 0 if x == \"negative\" else 1)\n",
        "    \n",
        "    return  df[\"review\"].values.tolist(), df[\"sentiment\"].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOoHO3beLpTJ"
      },
      "source": [
        "def load_fast_text_embeddings(filename: str):\n",
        "    \"\"\"Loads the FastText embeddings from the file with the given filename.\"\"\"\n",
        "    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = [float(x) for x in tokens[1:]]\n",
        "    \n",
        "    # dimension of the vector \n",
        "    dim = len(list(data.values())[0] )\n",
        "    return (data, dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyjp_GMPLpTJ"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "def tokenize_sentences(sentences: [str]):\n",
        "    \"\"\"Tokenizes the given sentences\"\"\"\n",
        "    result = []\n",
        "    for sen in sentences:\n",
        "        tokens =  word_tokenize(sen.lower())\n",
        "        tokens_without_sw = [token for token in tokens if token not in stopwords.words() and token not in string.punctuation]\n",
        "        result.append(tokens_without_sw)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUMS5G9uLpTK"
      },
      "source": [
        "def map_to_vectors(tokenized_sentences: [[str]]):\n",
        "    \"\"\"Maps the given tokenized sentences to lists of vectors.\"\"\"\n",
        "    \n",
        "    model = load_fast_text_embeddings(\"embeddings/wiki-news-300d-10k.vec\")\n",
        "    result = np.zeros((len(tokenized_sentences),300))\n",
        "    \n",
        "    for i, sentence in enumerate(tokenized_sentences):\n",
        "        sen_vec = np.zeros((len(sentence),300))\n",
        "        for idx, word in enumerate(sentence):\n",
        "            sen_vec[idx]= model[word]\n",
        "        sen_vec = np.mean(sen_vec,axis=0)\n",
        "        result[i]= sen_vec\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGMwfLYLpTK"
      },
      "source": [
        "# define a model\n",
        "def MLP(input_shape: np.array):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100,activation='relu',input_shape=input_shape))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(20,activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2,activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ARnQ_YzqnE6"
      },
      "source": [
        "reviews,sentiments=data_reader('data/IMDB.csv')\n",
        "# convert numeric labels to one hot vectors\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "sentiments=sentiments.reshape(len(sentiments),1)\n",
        "sentiments = onehot_encoder.fit_transform(sentiments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGz6iMbrqveF"
      },
      "source": [
        "token2vector, dimensions = load_fast_text_embeddings(filename=\"embeddings/wiki-news-300d-10k.vec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-4gUp0iqwIb"
      },
      "source": [
        "tokenized_reviews = tokenize_sentences(reviews)\n",
        "#visual inspection if a reasonable tokenization technique was applied for question (c)\n",
        "print('First Review')\n",
        "print(tokenized_reviews[0])\n",
        "print('Second Review')\n",
        "print(tokenized_reviews[5])\n",
        "print('Third Review')\n",
        "print(tokenized_reviews[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3bAwMv6Op11"
      },
      "source": [
        "(1 Point) point for implementing tokenize_sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHDz877BOf-_"
      },
      "source": [
        "# should be written by tutors\n",
        "point_for_c = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8v7FKsILpTL"
      },
      "source": [
        "embedded_reviews = map_to_vectors(tokenized_reviews)\n",
        "#TODO\n",
        "# split the vectorized reviews into train-, and testset\n",
        "train_test_split = 0.8\n",
        "train_x,train_y,test_x,test_y = train_test_split(embedded_reviews,sentiments, test_size = 1-train_test_split)\n",
        "#ENDTODO\n",
        "\n",
        "\n",
        "best_model = \"model/best_model.ckpt\"\n",
        "# train the model and save the best one on dev set\n",
        "cp_callback = callbacks.ModelCheckpoint(filepath=best_model, verbose=1, save_weights_only=True, monitor='val_acc', save_best_only=True)\n",
        "model = MLP(input_shape=(dimensions,))\n",
        "# use the binary cross entropy to measure the errors\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=20, batch_size=20, callbacks=[cp_callback], validation_split=0.2)\n",
        "\n",
        "model.load_weights(best_model)\n",
        "# calculate the accuracy on test set\n",
        "_,acc = model.evaluate(test_x,test_y)\n",
        "print('accuracy on test set:', acc)\n",
        "\n",
        "predictions=model.predict(test_x)\n",
        "# convert predictions to one hot vectors\n",
        "predictions_oneHot = np.where(predictions > 0.5, 1, 0)\n",
        "print(predictions_oneHot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRz0ofSNLpTM"
      },
      "source": [
        "(e)(4 Points) Check the functionMLP(input_shape:np.array)that defines our multi-layer perceptron (MLP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMuBC2zELpTM"
      },
      "source": [
        "(i)(1 Point) How many layers does this model have (including the input and the output layer)?\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDa_fCeZLpTN"
      },
      "source": [
        "# should be written by tutors\n",
        "point_for_e_i = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8kLx38DLpTO"
      },
      "source": [
        "(ii) (1 Point) What is the size of the matrix that connects the input layer and the first hidden layer? \n",
        "Answer: [100,300]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0cElAF2LpTO"
      },
      "source": [
        "# should be written by tutors\n",
        "point_for_e_ii = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yZejlDkLpTP"
      },
      "source": [
        "(iii) (1 Point) How many units/neurons are in the output layer? Why? \n",
        "Answer: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLJS8QvgLpTP"
      },
      "source": [
        "# should be written by tutors\n",
        "point_for_e_iii = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_rYzkXQLpTP"
      },
      "source": [
        "(iv) (1 Point)  What is the meaning of Dropout? \n",
        "Answer: dropout refers to ignoring units during the training phase of certain set of neurons which is chosen at random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrRN0jM9LpTQ"
      },
      "source": [
        "# should be written by tutors\n",
        "point_for_e_iv = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGvRVMzCLpTS"
      },
      "source": [
        "# the following codes are used for grading, students can simply ignore them, but please don't change/delete them\n",
        "# any modifications to the code are seen to be cheating\n",
        "import csv\n",
        "assertions = dict()\n",
        "with open('../assertions.csv',newline='') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        assertions[row['assertion sequence']] = row['content']\n",
        "\n",
        "total_points = 0\n",
        "#==========================================================\n",
        "# sanity check for question (a)\n",
        "#==========================================================\n",
        "try:\n",
        "    assert(assertions['a_1'] in reviews)\n",
        "    assert(sentiments[reviews.index(assertions['a_1'])][1]==1)\n",
        "    total_points += 1\n",
        "except AssertionError:\n",
        "    print('errors in your implementation for question (a)')\n",
        "\n",
        "try:\n",
        "    assert(total_points <= 1)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question (a)')\n",
        "\n",
        "#==========================================================\n",
        "# sanity check for question (b)\n",
        "#==========================================================\n",
        "try:\n",
        "    assert(dimensions == int(assertions['b_1']))\n",
        "    assert(token2vector['article'][0] == float(assertions['b_2']))\n",
        "    assert(token2vector['state'][2] == float(assertions['b_3']))\n",
        "    total_points += 1\n",
        "except AssertionError:\n",
        "    print('errors in your implementation for question (b)')\n",
        "\n",
        "\n",
        "try:\n",
        "    assert(total_points <= 2)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question (b)')\n",
        "    \n",
        "#==========================================================\n",
        "# sanity check for question (c)\n",
        "#==========================================================\n",
        "total_points += point_for_c \n",
        "try:\n",
        "    assert(total_points <= 3)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question (c)')\n",
        "    \n",
        "#==========================================================\n",
        "# sanity check for question (d)\n",
        "#==========================================================\n",
        "try:\n",
        "    assert(len(embedded_reviews[0]) == int(assertions['d_1']))\n",
        "    assert(len(embedded_reviews[100]) == int(assertions['d_2']))\n",
        "    assert(len(embedded_reviews[600]) == int(assertions['d_3']))\n",
        "    total_points += 1\n",
        "except AssertionError:\n",
        "    print('errors in your implementation for question (d)')\n",
        "\n",
        "try:\n",
        "    assert(total_points <= 4)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question (d)')\n",
        "\n",
        "points_for_first_four_questions = total_points\n",
        "\n",
        "#==========================================================\n",
        "# sanity check for question e(i)\n",
        "#==========================================================\n",
        "\n",
        "total_points += point_for_e_i \n",
        "try:\n",
        "    assert(total_points <= 5)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question e(i)')\n",
        "\n",
        "#==========================================================\n",
        "# sanity check for question e(ii)\n",
        "#==========================================================\n",
        "total_points += point_for_e_ii\n",
        "try:\n",
        "    assert(total_points <= 6)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question e(ii)')\n",
        "\n",
        "#==========================================================\n",
        "# sanity check for question e(iii)\n",
        "#==========================================================\n",
        "total_points += point_for_e_iii \n",
        "try:\n",
        "    assert(total_points <= 7)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question e(iii)')\n",
        "\n",
        "#==========================================================\n",
        "# sanity check for question e(iv)\n",
        "#==========================================================    \n",
        "total_points += point_for_e_iv \n",
        "try:\n",
        "    assert(total_points <= 8)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question e(iv)')\n",
        "\n",
        "\n",
        "#==========================================================\n",
        "# sanity check for question f\n",
        "#==========================================================\n",
        "point_for_f = 0\n",
        "try:\n",
        "    assert(len(train_x) > len(test_x))\n",
        "    assert(len(train_y) > len(test_y))\n",
        "    assert(len(train_x)+len(test_x)==len(embedded_reviews))\n",
        "    assert(len(train_y)+len(test_y)==len(sentiments))\n",
        "    point_for_f = 2\n",
        "    total_points += point_for_f\n",
        "except AssertionError:\n",
        "    print('errors in your implementation for question (f)')\n",
        "\n",
        "try:\n",
        "    assert(total_points <= 10)\n",
        "except AssertionError:\n",
        "    print('errors in calculating the points for question (f)')\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-STN17sLpTU"
      },
      "source": [
        "print(\"points for the first four questions: \",points_for_first_four_questions)\n",
        "print(\"point for e(i): \", point_for_e_i)\n",
        "print(\"point for e(ii): \", point_for_e_ii)\n",
        "print(\"point for e(iii): \", point_for_e_iii)\n",
        "print(\"point for e(iv): \", point_for_e_iv)\n",
        "print(\"point for f: \", point_for_f)\n",
        "print(\"total points: \", total_points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbvNsGfpLpTV"
      },
      "source": [
        "# the following codes can be run if you want to save the result of all grading to a .csv file\n",
        "# it can be run on the window system, but if you use colab, you need to at first locate to your current .ipynb file (cd xxx/xxx)\n",
        "import os\n",
        "# for windows users\n",
        "filename = os.getcwd().split('\\\\')[-1]\n",
        "#filename = os.getcwd().split('/')[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OBLG40hR6lz"
      },
      "source": [
        "# filename = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lNygyyWR5ph"
      },
      "source": [
        "# do you have any feedback\n",
        "feedback = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_qgCisELpTW"
      },
      "source": [
        "name = filename.split('_')[0]\n",
        "matrikelnr= filename.split('_')[1]\n",
        "#feedback += ' '.join([item for item in comments if len(item.strip())>0])\n",
        "with open('../grading_for_HW9.csv','a+',newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([name,matrikelnr,total_points,feedback])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}