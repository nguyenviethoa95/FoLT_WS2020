{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXTZ3sthLr87"
   },
   "source": [
    "# **FolT Handout 10**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZSfbVGqR5gr"
   },
   "outputs": [],
   "source": [
    "# Execute before and only in colab, if you use jupyter ignore this cell\n",
    "!pip install --target=$nb_path nltk==3.5\n",
    "!python3 -m nltk.downloader popular\n",
    "!python3 -m nltk.downloader book\n",
    "!python3 -m nltk.downloader words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eo3mepfqL17n"
   },
   "source": [
    "### 10.1 Warm up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI8WyzrqAcF6"
   },
   "source": [
    "**Question 10.1** Cross validation: Which of the following statements are true?\n",
    "\n",
    "1.   Cross validation means to take each \n",
    "2.   A fold is a subset of the original corpus.\n",
    "3.  Cross validation is an option if the test set is small.\n",
    "4.  Cross validation is useful to judge the accuracy of a classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHLAoLGFGasD"
   },
   "source": [
    "Add answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxaLxohsMQoZ"
   },
   "source": [
    "### 10.2 Spam Classification\n",
    "\n",
    "Spam emails are a major problem. In order to build a spam detector, we want to classify emails as SPAM or NOSPAM.\n",
    "As we have already learned about classification in the last tutorial, we can now try to tackle this new problem. This\n",
    "exercise will guide you through the major steps.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7mOxYYZBH6Y"
   },
   "source": [
    "**Task 10.1** This time, we want to use Precision, Recall, and F-Measure to evaluate the classifier. As mentioned in\n",
    "the lecture, Precision is defined as $P = \\frac{TP}{TP+FP}$ , Recall is defined as $R = \\frac{TP}{TP+FN}$, and F-Measure is defined as\n",
    "$F_1 = \\frac{2 \\cdot P \\cdot R}{P+R}$\n",
    "P+R . Thereby, TP means true positives, FP means false positives, and FN means false negatives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAHMadcKBK2u"
   },
   "source": [
    "(a) Implement a function ```compute_PRF(gold, predicted, class_label)``` that returns Precision, Recall, and\n",
    "F-Measure of the classifier. Thereby, gold should be a list of the gold standard class labels (i.e. SPAM or\n",
    "NOSPAM), predicted should be a list predicted class labels, and class_label is the class for which the evaluation\n",
    "measures should be computed (i.e. either SPAM or NOSPAM). Note, that you need to ensure that the ordering of\n",
    "class labels is the same in the two lists, i.e. that if the gold standard class label for file “a” is the first element in\n",
    "the list, the predicted class label for that file also needs to be the first element in the corresponding list.Add answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHBQkz0tHWrJ"
   },
   "outputs": [],
   "source": [
    "def compute_PRF(gold, predicted, class_label):\n",
    "  # add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLd-vsMmBLxb"
   },
   "source": [
    "(b) Discuss the trade off between precision and recall. Which is more important for spam classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YEvM8k_HnPY"
   },
   "source": [
    "Add answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-5Zt6IlHtTB"
   },
   "source": [
    "**Task 10.2** Test each evaluation method with a self-defined example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sO8aq-lTHxQy"
   },
   "outputs": [],
   "source": [
    "# add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9INxqFtHxaZ"
   },
   "source": [
    "**Task 10.3** We need to prepare the provided mails as a corpus, separated into the categories SPAM and NOSPAM.\n",
    "\n",
    "\n",
    "(a) Download the file “emails.zip” from Moodle and unzip it within the folder nltk_data/corpora. You should get\n",
    "a folder ’mails’ with sub-folders ’spam’ and ’nospam’. (If you do not know where to find this folder, you can use\n",
    "```print(nltk.data.path)``` - it will output a list of folders where NLTK will search for your corpora.)\n",
    "\n",
    "\n",
    "(b) We may load the mails in the same way as NLTK loads the movie_reviews: Use the CategorizedPlaintextCorpusReader,\n",
    "which inherits from both PlaintextCorpusReader and CategorizedCorpusReader to load the corpus\n",
    "as shown in the listing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0I9VKM2IO6a"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "from nltk.corpus.reader import CategorizedPlaintextCorpusReader\n",
    "\n",
    "mails = LazyCorpusLoader(\n",
    "    'mails', CategorizedPlaintextCorpusReader,\n",
    "    r'(?!\\.).*\\.txt', cat_pattern=r'(spam|nospam)/.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59LCuJb3IUzc"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from corpus_mails import mails\n",
    "\n",
    "print(mails.categories()) #['nospam', 'spam']\n",
    "print(len(mails.fileids('spam'))) #481\n",
    "print(len(mails.fileids('nospam'))) #2412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFD68BPVIZ2-"
   },
   "source": [
    "**Task 10.4** No programming required.\n",
    "Discuss, what might be interesting features to classify a given email as spam? Formulate at least four ideas. Take a\n",
    "look at the files to get a feeling for the provided data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-gg5bAnIcoP"
   },
   "source": [
    "Add answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMNxffQuIfGh"
   },
   "source": [
    "**Task 10.5** Implement a feature function and train a classifier for spam detection. Have a look at the most informative\n",
    "features. Evaluate your classifier according to Precision, Recall, and F-Measure. Remember to use a development set\n",
    "to be able to tune your features without looking at the final test set. Report your final evaluation results and discuss\n",
    "whether it is high enough to employ the classifier in a real anti-spam application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CU8kYfYvInDm"
   },
   "source": [
    "### 10.3 Cross-validation\n",
    "\n",
    "**Task 10.6** The cross-validation process consists of splitting the data in 10 (in general N) subsets of 10% each. We\n",
    "iterate the process of training/testing 10 times, each time withholding one subset of 10% for testing and training\n",
    "on the other 9 subsets. We then report the results of the accuracy as a table with rows: ```i``` (iteration number),\n",
    "```accuracy(i)``` – and summarize with the combined accuracy averaged over the ten experiments. Assume that we\n",
    "decided to split our corpus in 90% training and 10% testing data. Implement cross-validation with 10 subsets for\n",
    "```nltk.NaiveBayesClassifier``` that you developed for gender classification in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKX12ts1I5wu"
   },
   "outputs": [],
   "source": [
    "# add code"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "FolT_Handout_10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}